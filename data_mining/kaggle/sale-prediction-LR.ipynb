{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Sales - Time Series Forecasting\n",
    "赛题任务：利用2013年1月1日至2017年8月15日的厄瓜多尔地区不同商店不同商品类别不同日期的历史销售量，来预测2017年8月16日至2017年8月31日**不同商品在指定日期的销售额**。其中，时间序列预测就是利用过去一段时间的数据来预测未来一段时间内的信息。\n",
    "\n",
    "该机器学习任务是有监督学习（有训练数据、测试数据），由于是预测不同商品在指定日期的销售额，因此该学习任务是一个回归任务（给定商品和日期，输出销售额）。\n",
    "\n",
    "另外该任务的性能指标为均方根对数误差（Root Mean Squared Logarithmic Error，RMSLE）：\n",
    "\n",
    "$$\\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\hat{y}_i) - \\log (1 + y_i)\\right)^2}$$\n",
    "\n",
    "其中，$n$是实例的总数，$\\hat{y}_i$是目标的预测值，$y_i$是目标的实际值，$\\log$是自然对数（即以$e$为底）。\n",
    "\n",
    "下面开始对数据进行分析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train = pd.read_csv(\"./data/train.csv\")   # 读取训练数据\n",
    "#sales_train.head()\n",
    "#sales_train.info()\n",
    "#sales_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练数据中共有3000888条数据，每条数据有6个特征：\n",
    "+ id 表示商品唯一标识（int64）\n",
    "+ date 表示商品的销售日期（object）\n",
    "+ store_nbr 标识销售产品的商店（int64）\n",
    "+ family 标识所售产品的类型（object）\n",
    "+ sales 表示给定日期特定商店的产品系列的总销售额（float64）\n",
    "+ onpromotion 表示在给定日期在商店促销的产品系列中的商品总数（int64）\n",
    "\n",
    "比如数据(id=262935, date=2013/05/28, store_nbr=36, family=MEATS, sales=104.678, onpromotion=0)表示：\n",
    "商品262935，在2013/05/28这一天，在商店36中，作为MEATS，销售额为104.678，而2013/05/28这一天商店促销的MEATS的商品总数为0\n",
    "\n",
    "下面用直方图的形式来表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_train.hist(bins=50, figsize=(10, 7.5))  # 50列\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面进行数据清理的工作。\n",
    "\n",
    "注意到数据中可能有些异常情况，比如缺失某些属性等等，下面就来处理这一些情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sales_train.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们简单地测试了一下sales_train中各个特征的数量，可以看出数据都是完整的，是一种理想的情况。\n",
    "\n",
    "在开始训练之前，我们还要处理一下训练数据，我们需要将训练数据分成两部分：特征和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.将数据中的非数值属性转换为数值属性\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "sales_train_date = sales_train[[\"date\"]]\n",
    "sales_train[['date']] = ordinal_encoder.fit_transform(sales_train_date)\n",
    "sales_train_date = sales_train[[\"family\"]]\n",
    "sales_train[['family']] = ordinal_encoder.fit_transform(sales_train_date)\n",
    "\n",
    "sales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 2.将训练数据分为训练集和验证集-1\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_set_indices = shuffled_indices[:test_set_size]\n",
    "    train_set_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_set_indices], data.iloc[test_set_indices]\n",
    "\n",
    "sales_train_set, sales_test_set = split_train_test(sales_train, 0.2)\n",
    "\n",
    "print('len(sales_train_set)=', len(sales_train_set))\n",
    "print('len(sales_test_set)=', len(sales_test_set))\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 2.将训练数据分为训练集和验证集-2\n",
    "from zlib import crc32\n",
    "\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio*(2**32)\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "sales_train_set, sales_test_set = split_train_test_by_id(sales_train, 0.2, \"id\")\n",
    "\n",
    "print('len(sales_train_set)=', len(sales_train_set))\n",
    "print('len(sales_test_set)=', len(sales_test_set))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.将训练数据分为训练集和验证集-3\n",
    "from sklearn.model_selection import train_test_split\n",
    "sales_train_set, sales_test_set = train_test_split(sales_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('len(sales_train_set)=', len(sales_train_set))\n",
    "print('len(sales_test_set)=', len(sales_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.将训练数据分成特征部分和标签部分\n",
    "\n",
    "# 针对训练集\n",
    "sales_train_set_feature = sales_train_set[['id','date','store_nbr','family','onpromotion']]\n",
    "sales_train_set_label = sales_train_set.loc[:,['sales']]\n",
    "\n",
    "# 针对验证集\n",
    "sales_test_set_feature = sales_test_set[['id','date','store_nbr','family','onpromotion']]\n",
    "sales_test_set_label = sales_test_set.loc[:,['sales']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就开始训练阶段了，我们需要选择机器学习模型并展开训练了。\n",
    "\n",
    "首先，我们选择一个简单的模型：线性回归模型。这里需要利用的sklearn库里面的线性回归模型库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性回归模型训练\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(sales_train_set_feature, sales_train_set_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面训练出一个线性回归模型，下面利用测试集这个模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test = pd.read_csv(\"./data/test.csv\")\n",
    "sales_test_date = sales_test[['date']]\n",
    "sales_test[['date']] = ordinal_encoder.fit_transform(sales_test_date)\n",
    "sales_test_family = sales_test[['family']]\n",
    "sales_test[['family']] = ordinal_encoder.fit_transform(sales_test_family)\n",
    "sales_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_predict = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "sample_submission_predict = sample_submission_predict[['id', 'sales']]\n",
    "sample_submission_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_predict_sales = lin_reg.predict(sales_test)\n",
    "sample_submission_predict[['sales']] = sample_submission_predict_sales[:,np.newaxis]\n",
    "sample_submission_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_predict.to_csv(\"./data/sample_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
